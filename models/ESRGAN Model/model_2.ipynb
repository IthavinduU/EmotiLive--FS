{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thavi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Directories set up successfully!\n"
     ]
    }
   ],
   "source": [
    "# %% [Setup]\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import lpips\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Define paths\n",
    "temp_folder = 'tmp_frames'\n",
    "result_folder = 'results'\n",
    "\n",
    "# Clean existing folders\n",
    "for folder in [temp_folder, result_folder]:\n",
    "    if os.path.isdir(folder):\n",
    "        shutil.rmtree(folder)\n",
    "    os.mkdir(folder)\n",
    "\n",
    "print(\"✅ Directories set up successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎬 Selected Video: ds3_1.mp4\n"
     ]
    }
   ],
   "source": [
    "# %% [Select Video]\n",
    "input_path = r'D:\\University\\IIT\\Level 7\\Final Year Project\\MVP\\EmotiLive\\ESRGAN Model\\inputs\\ds3_1.mp4'\n",
    "\n",
    "if not os.path.exists(input_path):\n",
    "    raise ValueError(f\"❌ Video file not found: {input_path}\")\n",
    "\n",
    "file_name = os.path.basename(input_path)\n",
    "print(f\"🎬 Selected Video: {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Extracting frames from video...\n",
      "✅ Extracted 196 frames successfully!\n"
     ]
    }
   ],
   "source": [
    "# %% [Extract Frames]\n",
    "print(\"🔄 Extracting frames from video...\")\n",
    "\n",
    "cmd = [\n",
    "    'ffmpeg',\n",
    "    '-i', input_path,\n",
    "    '-vf', 'fps=15', \n",
    "    '-q:v', '1',       \n",
    "    f'{temp_folder}/frame_%08d.png'\n",
    "]\n",
    "\n",
    "process = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "frame_count = len(os.listdir(temp_folder))\n",
    "\n",
    "if process.returncode != 0 or frame_count == 0:\n",
    "    raise RuntimeError(\"❌ Error extracting frames\")\n",
    "\n",
    "print(f\"✅ Extracted {frame_count} frames successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Enhancing frames using Real-ESRGAN+...\n",
      "✅ Frame enhancement complete!\n"
     ]
    }
   ],
   "source": [
    "# %% [Enhance Frames with Real-ESRGAN+]\n",
    "print(\"🚀 Enhancing frames using Real-ESRGAN+...\")\n",
    "\n",
    "cmd = [\n",
    "    'python', 'inference_realesrgan.py',\n",
    "    '-n', 'RealESRGAN_x4plus_anime_6B',  \n",
    "    '-i', temp_folder,\n",
    "    '--outscale', '4',\n",
    "    '--face_enhance' \n",
    "]\n",
    "\n",
    "process = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "if process.returncode != 0:\n",
    "    raise RuntimeError(\"❌ Error enhancing frames\")\n",
    "\n",
    "print(\"✅ Frame enhancement complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧹 Applying denoising on enhanced frames...\n",
      "✅ Denoising complete!\n"
     ]
    }
   ],
   "source": [
    "# %% [Denoise Enhanced Frames]\n",
    "print(\"🧹 Applying denoising on enhanced frames...\")\n",
    "\n",
    "for frame_file in os.listdir(temp_folder):\n",
    "    if frame_file.endswith(\".png\"):\n",
    "        img_path = os.path.join(temp_folder, frame_file)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Apply Non-Local Means Denoising\n",
    "        denoised_img = cv2.fastNlMeansDenoisingColored(img, None, 10, 10, 7, 21)\n",
    "\n",
    "        # Save back the denoised frame\n",
    "        cv2.imwrite(img_path, denoised_img)\n",
    "\n",
    "print(\"✅ Denoising complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎥 Recreating video with high bitrate...\n",
      "FFmpeg Output: \n",
      "FFmpeg Error: ffmpeg version N-118892-ge5d62e20c8-20250321 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 14.2.0 (crosstool-NG 1.27.0.18_7458341)\n",
      "  configuration: --prefix=/ffbuild/prefix --pkg-config-flags=--static --pkg-config=pkg-config --cross-prefix=x86_64-w64-mingw32- --arch=x86_64 --target-os=mingw32 --enable-gpl --enable-version3 --disable-debug --enable-shared --disable-static --disable-w32threads --enable-pthreads --enable-iconv --enable-zlib --enable-libfreetype --enable-libfribidi --enable-gmp --enable-libxml2 --enable-lzma --enable-fontconfig --enable-libharfbuzz --enable-libvorbis --enable-opencl --disable-libpulse --enable-libvmaf --disable-libxcb --disable-xlib --enable-amf --enable-libaom --enable-libaribb24 --enable-avisynth --enable-chromaprint --enable-libdav1d --enable-libdavs2 --enable-libdvdread --enable-libdvdnav --disable-libfdk-aac --enable-ffnvcodec --enable-cuda-llvm --enable-frei0r --enable-libgme --enable-libkvazaar --enable-libaribcaption --enable-libass --enable-libbluray --enable-libjxl --enable-libmp3lame --enable-libopus --enable-librist --enable-libssh --enable-libtheora --enable-libvpx --enable-libwebp --enable-libzmq --enable-lv2 --enable-libvpl --enable-openal --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenh264 --enable-libopenjpeg --enable-libopenmpt --enable-librav1e --enable-librubberband --enable-schannel --enable-sdl2 --enable-libsnappy --enable-libsoxr --enable-libsrt --enable-libsvtav1 --enable-libtwolame --enable-libuavs3d --disable-libdrm --enable-vaapi --enable-libvidstab --enable-vulkan --enable-libshaderc --enable-libplacebo --disable-libvvenc --enable-libx264 --enable-libx265 --enable-libxavs2 --enable-libxvid --enable-libzimg --enable-libzvbi --extra-cflags=-DLIBTWOLAME_STATIC --extra-cxxflags= --extra-libs=-lgomp --extra-ldflags=-pthread --extra-ldexeflags= --cc=x86_64-w64-mingw32-gcc --cxx=x86_64-w64-mingw32-g++ --ar=x86_64-w64-mingw32-gcc-ar --ranlib=x86_64-w64-mingw32-gcc-ranlib --nm=x86_64-w64-mingw32-gcc-nm --extra-version=20250321\n",
      "  libavutil      59. 60.100 / 59. 60.100\n",
      "  libavcodec     61. 33.102 / 61. 33.102\n",
      "  libavformat    61.  9.107 / 61.  9.107\n",
      "  libavdevice    61.  4.100 / 61.  4.100\n",
      "  libavfilter    10.  9.100 / 10.  9.100\n",
      "  libswscale      8. 13.103 /  8. 13.103\n",
      "  libswresample   5.  4.100 /  5.  4.100\n",
      "  libpostproc    58.  4.100 / 58.  4.100\n",
      "Input #0, image2, from 'tmp_frames\\frame_%08d.png':\n",
      "  Duration: 00:00:13.07, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgb24(pc, gbr/unknown/unknown), 1280x720, 15 fps, 15 tbr, 15 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 00000239458fc900] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 00000239458fc900] profile High, level 3.1, 4:2:0, 8-bit\n",
      "[libx264 @ 00000239458fc900] 264 - core 164 - H.264/MPEG-4 AVC codec - Copyleft 2003-2025 - http://www.videolan.org/x264.html - options: cabac=1 ref=5 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=8 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=2 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=18 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=3 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=15 scenecut=40 intra_refresh=0 rc_lookahead=50 rc=crf mbtree=1 crf=18.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'results\\enhanced_ds3_1.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf61.9.107\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 1280x720, q=2-31, 8000 kb/s, 15 fps, 15360 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc61.33.102 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/8000000 buffer size: 0 vbv_delay: N/A\n",
      "frame=    0 fps=0.0 q=0.0 size=       0KiB time=N/A bitrate=N/A speed=N/A    \n",
      "frame=   13 fps= 13 q=22.0 size=       0KiB time=00:00:00.73 bitrate=   0.5kbits/s speed=0.707x    \n",
      "frame=   37 fps= 24 q=22.0 size=     256KiB time=00:00:02.33 bitrate= 898.9kbits/s speed= 1.5x    \n",
      "frame=   68 fps= 33 q=22.0 size=     768KiB time=00:00:04.40 bitrate=1430.0kbits/s speed=2.12x    \n",
      "frame=   97 fps= 37 q=22.0 size=    1280KiB time=00:00:06.33 bitrate=1655.7kbits/s speed=2.45x    \n",
      "frame=  121 fps= 39 q=22.0 size=    1536KiB time=00:00:07.93 bitrate=1586.1kbits/s speed=2.55x    \n",
      "frame=  159 fps= 44 q=22.0 size=    2048KiB time=00:00:10.46 bitrate=1603.0kbits/s speed=2.89x    \n",
      "[out#0/mp4 @ 0000023943530ec0] video:2447KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.129085%\n",
      "frame=  196 fps= 50 q=-1.0 Lsize=    2451KiB time=00:00:12.93 bitrate=1552.2kbits/s speed= 3.3x    \n",
      "[libx264 @ 00000239458fc900] frame I:1     Avg QP:14.27  size: 94391\n",
      "[libx264 @ 00000239458fc900] frame P:49    Avg QP:14.81  size: 33105\n",
      "[libx264 @ 00000239458fc900] frame B:146   Avg QP:18.67  size:  5403\n",
      "[libx264 @ 00000239458fc900] consecutive B-frames:  0.5%  0.0%  1.5% 98.0%\n",
      "[libx264 @ 00000239458fc900] mb I  I16..4: 14.9% 40.7% 44.4%\n",
      "[libx264 @ 00000239458fc900] mb P  I16..4:  1.5%  3.1%  1.9%  P16..4: 33.1% 22.3% 13.6%  0.0%  0.0%    skip:24.6%\n",
      "[libx264 @ 00000239458fc900] mb B  I16..4:  0.1%  0.2%  0.1%  B16..8: 31.0%  6.4%  1.5%  direct: 1.9%  skip:58.8%  L0:41.5% L1:47.5% BI:10.9%\n",
      "[libx264 @ 00000239458fc900] 8x8 transform intra:45.5% inter:31.1%\n",
      "[libx264 @ 00000239458fc900] direct mvs  spatial:93.2% temporal:6.8%\n",
      "[libx264 @ 00000239458fc900] coded y,uvDC,uvAC intra: 42.5% 60.7% 43.5% inter: 9.7% 9.5% 1.0%\n",
      "[libx264 @ 00000239458fc900] i16 v,h,dc,p: 38% 39%  5% 18%\n",
      "[libx264 @ 00000239458fc900] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14% 20% 26%  4%  7%  6% 10%  5%  8%\n",
      "[libx264 @ 00000239458fc900] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 19% 15%  5%  9%  8% 10%  7%  9%\n",
      "[libx264 @ 00000239458fc900] i8c dc,h,v,p: 44% 30% 18%  9%\n",
      "[libx264 @ 00000239458fc900] Weighted P-Frames: Y:8.2% UV:4.1%\n",
      "[libx264 @ 00000239458fc900] ref P L0: 54.7%  8.8% 20.3%  7.4%  8.1%  0.6%\n",
      "[libx264 @ 00000239458fc900] ref B L0: 79.6% 13.4%  5.2%  1.8%\n",
      "[libx264 @ 00000239458fc900] ref B L1: 94.5%  5.5%\n",
      "[libx264 @ 00000239458fc900] kb/s:1533.93\n",
      "\n",
      "✅ Enhanced video saved as: results\\enhanced_ds3_1.mp4\n"
     ]
    }
   ],
   "source": [
    "# %% [Recreate Video with Higher Bitrate]\n",
    "print(\"🎥 Recreating video with high bitrate...\")\n",
    "\n",
    "output_video = os.path.join(result_folder, f\"enhanced_{file_name}\")\n",
    "fps = 15 \n",
    "\n",
    "cmd = [\n",
    "    'ffmpeg',\n",
    "    '-framerate', str(fps),\n",
    "    '-i', os.path.join(temp_folder, 'frame_%08d.png'),\n",
    "    '-c:v', 'libx264',\n",
    "    '-preset', 'slow',\n",
    "    '-crf', '18',  \n",
    "    '-b:v', '8000k',  \n",
    "    '-r', str(fps),\n",
    "    '-pix_fmt', 'yuv420p',\n",
    "    output_video\n",
    "]\n",
    "\n",
    "process = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "print(\"FFmpeg Output:\", process.stdout)\n",
    "print(\"FFmpeg Error:\", process.stderr)\n",
    "\n",
    "if process.returncode != 0:\n",
    "    raise RuntimeError(f\"❌ Error recreating video. FFmpeg Error:\\n{process.stderr}\")\n",
    "\n",
    "print(f\"✅ Enhanced video saved as: {output_video}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Initializing quality metrics...\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thavi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\thavi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: c:\\Users\\thavi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n",
      "✅ Quality metrics initialized!\n"
     ]
    }
   ],
   "source": [
    "# %% [Define Quality Metrics]\n",
    "print(\"📊 Initializing quality metrics...\")\n",
    "\n",
    "lpips_loss = lpips.LPIPS(net='alex')\n",
    "\n",
    "def compute_psnr(image1, image2):\n",
    "    mse = np.mean((image1 - image2) ** 2)\n",
    "    return 100 if mse == 0 else 20 * np.log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def compute_ssim(image1, image2):\n",
    "    return ssim(image1, image2, data_range=255, channel_axis=-1)\n",
    "\n",
    "def compute_mse(image1, image2):\n",
    "    return np.mean((image1 - image2) ** 2)\n",
    "\n",
    "def compute_lpips(image1, image2):\n",
    "    image1 = torch.from_numpy(image1).float().permute(2, 0, 1).unsqueeze(0) / 255.0\n",
    "    image2 = torch.from_numpy(image2).float().permute(2, 0, 1).unsqueeze(0) / 255.0\n",
    "    return lpips_loss(image1, image2).item()\n",
    "\n",
    "print(\"✅ Quality metrics initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [Initialize VGG Perceptual Loss]\n",
    "vgg_model = models.vgg19(pretrained=True).features[:16].eval().to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def compute_vgg_loss(image1, image2):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    image1 = transform(image1).unsqueeze(0).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    image2 = transform(image2).unsqueeze(0).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features1 = vgg_model(image1)\n",
    "        features2 = vgg_model(image2)\n",
    "    \n",
    "    return nn.functional.mse_loss(features1, features2).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: c:\\Users\\thavi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n",
      "✅ Quality metric functions initialized!\n"
     ]
    }
   ],
   "source": [
    "# %% [Import Necessary Libraries]\n",
    "import torch\n",
    "import lpips\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Initialize LPIPS loss function\n",
    "lpips_loss = lpips.LPIPS(net='alex')\n",
    "\n",
    "# %% [Define Quality Metrics Functions]\n",
    "def compute_psnr(image1, image2):\n",
    "    \"\"\" Compute Peak Signal-to-Noise Ratio (PSNR) \"\"\"\n",
    "    mse = np.mean((image1 - image2) ** 2)\n",
    "    return 100 if mse == 0 else 20 * np.log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "def compute_ssim(image1, image2):\n",
    "    \"\"\" Compute Structural Similarity Index (SSIM) \"\"\"\n",
    "    return ssim(image1, image2, data_range=255, channel_axis=-1)\n",
    "\n",
    "def compute_mse(image1, image2):\n",
    "    \"\"\" Compute Mean Squared Error (MSE) \"\"\"\n",
    "    return np.mean((image1 - image2) ** 2)\n",
    "\n",
    "def compute_lpips(image1, image2):\n",
    "    \"\"\" Compute Perceptual Loss using LPIPS \"\"\"\n",
    "    image1 = torch.from_numpy(image1).float().permute(2, 0, 1).unsqueeze(0) / 255.0\n",
    "    image2 = torch.from_numpy(image2).float().permute(2, 0, 1).unsqueeze(0) / 255.0\n",
    "    return lpips_loss(image1, image2).item()\n",
    "\n",
    "def compute_vgg_loss(image1, image2):\n",
    "    \"\"\" Dummy VGG Loss function (Future implementation) \"\"\"\n",
    "    return compute_lpips(image1, image2)  # Using LPIPS as a proxy\n",
    "\n",
    "print(\"✅ Quality metric functions initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📸 Processing frame 1...\n",
      "📸 Processing frame 2...\n",
      "📸 Processing frame 3...\n",
      "📸 Processing frame 4...\n",
      "📸 Processing frame 5...\n",
      "📸 Processing frame 6...\n",
      "📸 Processing frame 7...\n",
      "📸 Processing frame 8...\n",
      "📸 Processing frame 9...\n",
      "📸 Processing frame 10...\n",
      "📸 Processing frame 11...\n",
      "📸 Processing frame 12...\n",
      "📸 Processing frame 13...\n",
      "📸 Processing frame 14...\n",
      "📸 Processing frame 15...\n",
      "📸 Processing frame 16...\n",
      "📸 Processing frame 17...\n",
      "📸 Processing frame 18...\n",
      "📸 Processing frame 19...\n",
      "📸 Processing frame 20...\n",
      "📸 Processing frame 21...\n",
      "📸 Processing frame 22...\n",
      "📸 Processing frame 23...\n",
      "📸 Processing frame 24...\n",
      "📸 Processing frame 25...\n",
      "📸 Processing frame 26...\n",
      "📸 Processing frame 27...\n",
      "📸 Processing frame 28...\n",
      "📸 Processing frame 29...\n",
      "📸 Processing frame 30...\n",
      "📸 Processing frame 31...\n",
      "📸 Processing frame 32...\n",
      "📸 Processing frame 33...\n",
      "📸 Processing frame 34...\n",
      "📸 Processing frame 35...\n",
      "📸 Processing frame 36...\n",
      "📸 Processing frame 37...\n",
      "📸 Processing frame 38...\n",
      "📸 Processing frame 39...\n",
      "📸 Processing frame 40...\n",
      "📸 Processing frame 41...\n",
      "📸 Processing frame 42...\n",
      "📸 Processing frame 43...\n",
      "📸 Processing frame 44...\n",
      "📸 Processing frame 45...\n",
      "📸 Processing frame 46...\n",
      "📸 Processing frame 47...\n",
      "📸 Processing frame 48...\n",
      "📸 Processing frame 49...\n",
      "📸 Processing frame 50...\n",
      "📸 Processing frame 51...\n",
      "📸 Processing frame 52...\n",
      "📸 Processing frame 53...\n",
      "📸 Processing frame 54...\n",
      "📸 Processing frame 55...\n",
      "📸 Processing frame 56...\n",
      "📸 Processing frame 57...\n",
      "📸 Processing frame 58...\n",
      "📸 Processing frame 59...\n",
      "📸 Processing frame 60...\n",
      "📸 Processing frame 61...\n",
      "📸 Processing frame 62...\n",
      "📸 Processing frame 63...\n",
      "📸 Processing frame 64...\n",
      "📸 Processing frame 65...\n",
      "📸 Processing frame 66...\n",
      "📸 Processing frame 67...\n",
      "📸 Processing frame 68...\n",
      "📸 Processing frame 69...\n",
      "📸 Processing frame 70...\n",
      "📸 Processing frame 71...\n",
      "📸 Processing frame 72...\n",
      "📸 Processing frame 73...\n",
      "📸 Processing frame 74...\n",
      "📸 Processing frame 75...\n",
      "📸 Processing frame 76...\n",
      "📸 Processing frame 77...\n",
      "📸 Processing frame 78...\n",
      "📸 Processing frame 79...\n",
      "📸 Processing frame 80...\n",
      "📸 Processing frame 81...\n",
      "📸 Processing frame 82...\n",
      "📸 Processing frame 83...\n",
      "📸 Processing frame 84...\n",
      "📸 Processing frame 85...\n",
      "📸 Processing frame 86...\n",
      "📸 Processing frame 87...\n",
      "📸 Processing frame 88...\n",
      "📸 Processing frame 89...\n",
      "📸 Processing frame 90...\n",
      "📸 Processing frame 91...\n",
      "📸 Processing frame 92...\n",
      "📸 Processing frame 93...\n",
      "📸 Processing frame 94...\n",
      "📸 Processing frame 95...\n",
      "📸 Processing frame 96...\n",
      "📸 Processing frame 97...\n",
      "📸 Processing frame 98...\n",
      "📸 Processing frame 99...\n",
      "📸 Processing frame 100...\n",
      "📸 Processing frame 101...\n",
      "📸 Processing frame 102...\n",
      "📸 Processing frame 103...\n",
      "📸 Processing frame 104...\n",
      "📸 Processing frame 105...\n",
      "📸 Processing frame 106...\n",
      "📸 Processing frame 107...\n",
      "📸 Processing frame 108...\n",
      "📸 Processing frame 109...\n",
      "📸 Processing frame 110...\n",
      "📸 Processing frame 111...\n",
      "📸 Processing frame 112...\n",
      "📸 Processing frame 113...\n",
      "📸 Processing frame 114...\n",
      "📸 Processing frame 115...\n",
      "📸 Processing frame 116...\n",
      "📸 Processing frame 117...\n",
      "📸 Processing frame 118...\n",
      "📸 Processing frame 119...\n",
      "📸 Processing frame 120...\n",
      "📸 Processing frame 121...\n",
      "📸 Processing frame 122...\n",
      "📸 Processing frame 123...\n",
      "📸 Processing frame 124...\n",
      "📸 Processing frame 125...\n",
      "📸 Processing frame 126...\n",
      "📸 Processing frame 127...\n",
      "📸 Processing frame 128...\n",
      "📸 Processing frame 129...\n",
      "📸 Processing frame 130...\n",
      "📸 Processing frame 131...\n",
      "📸 Processing frame 132...\n",
      "📸 Processing frame 133...\n",
      "📸 Processing frame 134...\n",
      "📸 Processing frame 135...\n",
      "📸 Processing frame 136...\n",
      "📸 Processing frame 137...\n",
      "📸 Processing frame 138...\n",
      "📸 Processing frame 139...\n",
      "📸 Processing frame 140...\n",
      "📸 Processing frame 141...\n",
      "📸 Processing frame 142...\n",
      "📸 Processing frame 143...\n",
      "📸 Processing frame 144...\n",
      "📸 Processing frame 145...\n",
      "📸 Processing frame 146...\n",
      "📸 Processing frame 147...\n",
      "📸 Processing frame 148...\n",
      "📸 Processing frame 149...\n",
      "📸 Processing frame 150...\n",
      "📸 Processing frame 151...\n",
      "📸 Processing frame 152...\n",
      "📸 Processing frame 153...\n",
      "📸 Processing frame 154...\n",
      "📸 Processing frame 155...\n",
      "📸 Processing frame 156...\n",
      "📸 Processing frame 157...\n",
      "📸 Processing frame 158...\n",
      "📸 Processing frame 159...\n",
      "📸 Processing frame 160...\n",
      "📸 Processing frame 161...\n",
      "📸 Processing frame 162...\n",
      "📸 Processing frame 163...\n",
      "📸 Processing frame 164...\n",
      "📸 Processing frame 165...\n",
      "📸 Processing frame 166...\n",
      "📸 Processing frame 167...\n",
      "📸 Processing frame 168...\n",
      "📸 Processing frame 169...\n",
      "📸 Processing frame 170...\n",
      "📸 Processing frame 171...\n",
      "📸 Processing frame 172...\n",
      "📸 Processing frame 173...\n",
      "📸 Processing frame 174...\n",
      "📸 Processing frame 175...\n",
      "📸 Processing frame 176...\n",
      "📸 Processing frame 177...\n",
      "📸 Processing frame 178...\n",
      "📸 Processing frame 179...\n",
      "📸 Processing frame 180...\n",
      "📸 Processing frame 181...\n",
      "📸 Processing frame 182...\n",
      "📸 Processing frame 183...\n",
      "📸 Processing frame 184...\n",
      "📸 Processing frame 185...\n",
      "📸 Processing frame 186...\n",
      "📸 Processing frame 187...\n",
      "📸 Processing frame 188...\n",
      "📸 Processing frame 189...\n",
      "📸 Processing frame 190...\n",
      "📸 Processing frame 191...\n",
      "📸 Processing frame 192...\n",
      "📸 Processing frame 193...\n",
      "📸 Processing frame 194...\n",
      "📸 Processing frame 195...\n",
      "📸 Processing frame 196...\n",
      "\n",
      "=== 🎯 Video Quality Comparison Results ===\n",
      "📌 Average PSNR:  33.74 dB (Higher is better)\n",
      "📌 Average SSIM:  0.8574 (1.0 = Perfect match)\n",
      "📌 Average MSE:   29.39 (Lower is better)\n",
      "📌 Average LPIPS: 0.1014 (Lower is better, deep-learning based)\n",
      "📌 Average VGG Loss: 0.1014 (Lower means better perceptual similarity)\n"
     ]
    }
   ],
   "source": [
    "# %% [Compare Videos]\n",
    "def compare_videos(original_video_path, enhanced_video_path):\n",
    "    original_video = cv2.VideoCapture(original_video_path)\n",
    "    enhanced_video = cv2.VideoCapture(enhanced_video_path)\n",
    "\n",
    "    psnr_values, ssim_values, mse_values, lpips_values, vgg_loss_values = [], [], [], [], []\n",
    "    frame_count = 0\n",
    "\n",
    "    while original_video.isOpened() and enhanced_video.isOpened():\n",
    "        ret1, frame1 = original_video.read()\n",
    "        ret2, frame2 = enhanced_video.read()\n",
    "\n",
    "        if not ret1 or not ret2:\n",
    "            break  # Stop when no more frames\n",
    "\n",
    "        # Ensure both frames have the same dimensions\n",
    "        frame1 = cv2.resize(frame1, (640, 640))\n",
    "        frame2 = cv2.resize(frame2, (640, 640))\n",
    "\n",
    "        frame_count += 1\n",
    "        print(f\"📸 Processing frame {frame_count}...\")\n",
    "\n",
    "        # Compute quality metrics\n",
    "        psnr = compute_psnr(frame1, frame2)\n",
    "        ssim_value = compute_ssim(frame1, frame2)\n",
    "        mse_value = compute_mse(frame1, frame2)\n",
    "        lpips_value = compute_lpips(frame1, frame2)\n",
    "        vgg_loss_value = compute_vgg_loss(frame1, frame2)\n",
    "\n",
    "        # Append results\n",
    "        psnr_values.append(psnr)\n",
    "        ssim_values.append(ssim_value)\n",
    "        mse_values.append(mse_value)\n",
    "        lpips_values.append(lpips_value)\n",
    "        vgg_loss_values.append(vgg_loss_value)\n",
    "\n",
    "    original_video.release()\n",
    "    enhanced_video.release()\n",
    "\n",
    "    # Print Average Results\n",
    "    print(\"\\n=== 🎯 Video Quality Comparison Results ===\")\n",
    "    print(f\"📌 Average PSNR:  {np.mean(psnr_values):.2f} dB (Higher is better)\")\n",
    "    print(f\"📌 Average SSIM:  {np.mean(ssim_values):.4f} (1.0 = Perfect match)\")\n",
    "    print(f\"📌 Average MSE:   {np.mean(mse_values):.2f} (Lower is better)\")\n",
    "    print(f\"📌 Average LPIPS: {np.mean(lpips_values):.4f} (Lower is better, deep-learning based)\")\n",
    "    print(f\"📌 Average VGG Loss: {np.mean(vgg_loss_values):.4f} (Lower means better perceptual similarity)\")\n",
    "\n",
    "# Run comparison\n",
    "compare_videos(input_path, output_video)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
